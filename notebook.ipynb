{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase 1 : Veille et exploration théorique**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation croisée (cross-validation)\n",
    "\n",
    "**1. Concepts de base**\n",
    "\n",
    "*Qu’est-ce que la validation croisée et pourquoi est-elle importante ?*\n",
    "\n",
    "La validation croisée est une technique utilisée pour évaluer la performance d’un modèle en le testant sur plusieurs sous-ensembles de données. Elle permet de mieux généraliser les résultats en comparant les performances sur des données non vues et réduit le risque de surapprentissage ou de sous-apprentissage.\n",
    "\n",
    "*Différence entre validation simple (train/test split) et validation croisée :*\n",
    "\n",
    " - Validation simple : Divise les données en deux ensembles (entraînement et test). Cela peut mener à des biais si l'échantillon est petit ou non représentatif.\n",
    " - Validation croisée : Divise les données en plusieurs sous-ensembles (ou folds), entraîne le modèle sur certains et le teste sur d’autres, pour obtenir une évaluation plus robuste.\n",
    "\n",
    "**2. Types de validation croisée**\n",
    "\n",
    "*Différences entre les techniques :*\n",
    "\n",
    " - k-fold cross-validation : Divise les données en k sous-ensembles égaux. Chaque sous-ensemble sert une fois de test, et les autres de train.\n",
    " - Leave-One-Out Cross-Validation (LOOCV) : Cas particulier de k-fold où k est égal à la taille des données. Chaque observation est tour à tour utilisée comme ensemble de test.\n",
    " - Stratified k-fold cross-validation : Variante du k-fold qui maintient la proportion des classes dans chaque pli, utile pour les ensembles déséquilibrés.\n",
    " - Quand utiliser stratified k-fold ? Lorsque les classes sont déséquilibrées, le stratified k-fold assure une meilleure représentativité des classes dans chaque pli.\n",
    "\n",
    "**3. Applications et limites**\n",
    "\n",
    "*Avantages et inconvénients pour les données déséquilibrées :*\n",
    " - Avantages : Assure que toutes les classes sont bien représentées dans les données d’entraînement et de test.\n",
    " - Inconvénients : Peut devenir coûteux en temps de calcul sur de grands ensembles de données.\n",
    "\n",
    "*Comment la validation croisée évite le surapprentissage ?*\n",
    "En testant le modèle sur plusieurs sous-ensembles non vus, elle détecte si un modèle est trop spécifique aux données d’entraînement.\n",
    "\n",
    "**4. Métriques et résultats**\n",
    "\n",
    "Score moyen lors d’une validation croisée : Il représente la performance moyenne du modèle sur tous les plis, donnant une évaluation générale de ses capacités de généralisation.\n",
    "\n",
    "**Interprétation de la variance des scores entre les plis :**\n",
    "\n",
    " - Faible variance : Le modèle est robuste et généralise bien.\n",
    " - Forte variance : Les performances varient beaucoup selon les sous-ensembles, indiquant une possible instabilité du modèle ou une mauvaise représentativité des données.\n",
    "\n",
    "**Optimisation des hyperparamètres (GridSearchCV et RandomizedSearchCV)**\n",
    "\n",
    "**1. Concepts de base**\n",
    "\n",
    "*Différence entre paramètres et hyperparamètres :*\n",
    "\n",
    " - Paramètres : Déterminés par l’apprentissage, comme les poids dans une régression linéaire.\n",
    " - Hyperparamètres : Définis avant l’entraînement, comme le taux d’apprentissage ou la profondeur d’un arbre de décision.\n",
    "\n",
    "*Pourquoi les hyperparamètres nécessitent-ils une optimisation séparée ?*\n",
    "Ils ne sont pas appris directement, mais influencent le processus d’apprentissage et doivent être ajustés pour maximiser la performance du modèle.\n",
    "\n",
    "**2. Approches d’optimisation**\n",
    "\n",
    "Fonctionnement de GridSearchCV : Explore toutes les combinaisons possibles d’hyperparamètres dans un espace défini.\n",
    " - Avantages : Explore exhaustivement toutes les options.\n",
    " - Inconvénients : Coûteux en temps et en calcul.\n",
    "\n",
    "Différences avec RandomizedSearchCV : RandomizedSearchCV échantillonne un nombre défini de combinaisons aléatoires.\n",
    " - Avantages : Plus rapide pour les espaces de recherche larges.\n",
    " - Cas préférés : Lorsque le coût computationnel est élevé ou si certaines dimensions de l’espace sont moins critiques.\n",
    "\n",
    "*Facteurs influençant le choix de la méthode :*\n",
    " - Taille des données.\n",
    " - Complexité du modèle.\n",
    " - Ressources computationnelles disponibles.\n",
    "\n",
    "**3. Configuration et choix**\n",
    "\n",
    "Paramètre cv dans GridSearchCV : Définit le type de validation croisée (par exemple, k-fold). Il est critique pour garantir une évaluation robuste.\n",
    "\n",
    "Choix des hyperparamètres et plages de valeurs : \n",
    "Basé sur :\n",
    " - La connaissance du modèle (ex. : C dans une SVM pour régularisation).\n",
    " - Des tests exploratoires pour limiter les plages.\n",
    "\n",
    "**4. Problèmes courants**\n",
    "\n",
    "*Risques d’une mauvaise configuration dans GridSearchCV :*\n",
    " - Sur-apprentissage si le même ensemble est utilisé pour la sélection d’hyperparamètres et l’évaluation finale.\n",
    " - Temps de calcul excessif avec trop de combinaisons.\n",
    "\n",
    "*Data leakage :*\n",
    " - Définition : Informations des données de test influencent les données d’entraînement.\n",
    " - Prévention : Appliquer la validation croisée de manière rigoureuse sans utiliser les données de test pour ajuster les hyperparamètres.\n",
    "\n",
    "**5. Métriques et performance**\n",
    "\n",
    "Évaluation des modèles optimisés : Utiliser des données de test séparées pour évaluer la performance après optimisation.\n",
    "Choix de métriques spécifiques :\n",
    " - Accuracy : Pour les données équilibrées.\n",
    " - F1-score : Pour les ensembles déséquilibrés, car il équilibre précision et rappel."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
